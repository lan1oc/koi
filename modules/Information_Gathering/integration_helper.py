#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿¡æ¯æ”¶é›†æ¨¡å—é›†æˆåŠ©æ‰‹
ç”¨äºå°†æ¨¡å—åŒ–çš„ä¿¡æ¯æ”¶é›†åŠŸèƒ½é›†æˆåˆ°ä¸»ç¨‹åºä¸­
"""

from PySide6.QtWidgets import QTabWidget, QWidget, QVBoxLayout, QMessageBox
from typing import Optional
import logging


def integrate_information_gathering_to_main_window(main_window) -> bool:
    """
    å°†ä¿¡æ¯æ”¶é›†åŠŸèƒ½é›†æˆåˆ°ä¸»çª—å£
    
    Args:
        main_window: ä¸»çª—å£å®ä¾‹
        
    Returns:
        bool: é›†æˆæ˜¯å¦æˆåŠŸ
    """
    try:
        # æ£€æŸ¥ä¸»çª—å£æ˜¯å¦æœ‰tab_widgetå±æ€§
        if not hasattr(main_window, 'tab_widget'):
            logging.error("ä¸»çª—å£ç¼ºå°‘tab_widgetå±æ€§")
            return False
        
        # å¯¼å…¥ä¿¡æ¯æ”¶é›†UIç»„ä»¶
        from .information_gathering_ui import InformationGatheringUI
        
        # åˆ›å»ºä¿¡æ¯æ”¶é›†UIå®ä¾‹
        info_gathering_ui = InformationGatheringUI(main_window)
        
        # åŠ è½½é…ç½®æ–‡ä»¶å¹¶è®¾ç½®åˆ°å­ç»„ä»¶
        if hasattr(main_window, 'load_unified_config'):
            config = main_window.load_unified_config()
            if config:
                # è½¬æ¢é…ç½®æ ¼å¼ä»¥é€‚é…ä¿¡æ¯æ”¶é›†æ¨¡å—
                info_config = {
                    'enterprise': {
                        'tianyancha_cookie': config.get('tyc', {}).get('cookie', ''),
                        'aiqicha_cookie': config.get('aiqicha', {}).get('cookie', '')
                    },
                    'asset': {
                        'fofa_api_key': config.get('fofa', {}).get('api_key', ''),
                        'fofa_email': config.get('fofa', {}).get('email', ''),
                        'hunter_api_key': config.get('hunter', {}).get('api_key', ''),
                        'quake_api_key': config.get('quake', {}).get('api_key', '')
                    }
                }
                info_gathering_ui.set_config(info_config)
        
        # å°†ä¿¡æ¯æ”¶é›†æ ‡ç­¾é¡µæ·»åŠ åˆ°ä¸»çª—å£
        main_window.tab_widget.addTab(info_gathering_ui, "ğŸ” ä¿¡æ¯æ”¶é›†")
        
        # ä¿å­˜å¼•ç”¨ä»¥ä¾¿åç»­ä½¿ç”¨
        main_window.information_gathering_ui = info_gathering_ui
        
        logging.info("ä¿¡æ¯æ”¶é›†æ¨¡å—é›†æˆæˆåŠŸ")
        return True
        
    except ImportError as e:
        logging.error(f"å¯¼å…¥ä¿¡æ¯æ”¶é›†æ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logging.error(f"é›†æˆä¿¡æ¯æ”¶é›†æ¨¡å—å¤±è´¥: {e}")
        return False


def integrate_information_gathering_to_tab_widget(tab_widget: QTabWidget) -> bool:
    """
    å°†ä¿¡æ¯æ”¶é›†åŠŸèƒ½é›†æˆåˆ°æŒ‡å®šçš„æ ‡ç­¾é¡µæ§ä»¶
    
    Args:
        tab_widget: æ ‡ç­¾é¡µæ§ä»¶å®ä¾‹
        
    Returns:
        bool: é›†æˆæ˜¯å¦æˆåŠŸ
    """
    try:
        # å¯¼å…¥ä¿¡æ¯æ”¶é›†UIç»„ä»¶
        from .information_gathering_ui import InformationGatheringUI
        
        # åˆ›å»ºä¿¡æ¯æ”¶é›†UIå®ä¾‹
        info_gathering_ui = InformationGatheringUI()
        
        # å°†ä¿¡æ¯æ”¶é›†æ ‡ç­¾é¡µæ·»åŠ åˆ°æ ‡ç­¾é¡µæ§ä»¶
        tab_widget.addTab(info_gathering_ui, "ğŸ” ä¿¡æ¯æ”¶é›†")
        
        logging.info("ä¿¡æ¯æ”¶é›†æ¨¡å—é›†æˆåˆ°æ ‡ç­¾é¡µæ§ä»¶æˆåŠŸ")
        return True
        
    except ImportError as e:
        logging.error(f"å¯¼å…¥ä¿¡æ¯æ”¶é›†æ¨¡å—å¤±è´¥: {e}")
        return False
    except Exception as e:
        logging.error(f"é›†æˆä¿¡æ¯æ”¶é›†æ¨¡å—åˆ°æ ‡ç­¾é¡µæ§ä»¶å¤±è´¥: {e}")
        return False


def create_standalone_information_gathering_window(parent=None) -> Optional[QWidget]:
    """
    åˆ›å»ºç‹¬ç«‹çš„ä¿¡æ¯æ”¶é›†çª—å£
    
    Args:
        parent: çˆ¶çª—å£
        
    Returns:
        QWidget: ä¿¡æ¯æ”¶é›†çª—å£å®ä¾‹ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    try:
        # å¯¼å…¥ä¿¡æ¯æ”¶é›†UIç»„ä»¶
        from .information_gathering_ui import InformationGatheringUI
        
        # åˆ›å»ºä¿¡æ¯æ”¶é›†UIå®ä¾‹
        info_gathering_ui = InformationGatheringUI(parent)
        info_gathering_ui.setWindowTitle("ä¿¡æ¯æ”¶é›†å·¥å…·")
        info_gathering_ui.resize(1200, 800)
        
        logging.info("åˆ›å»ºç‹¬ç«‹ä¿¡æ¯æ”¶é›†çª—å£æˆåŠŸ")
        return info_gathering_ui
        
    except ImportError as e:
        logging.error(f"å¯¼å…¥ä¿¡æ¯æ”¶é›†æ¨¡å—å¤±è´¥: {e}")
        return None
    except Exception as e:
        logging.error(f"åˆ›å»ºç‹¬ç«‹ä¿¡æ¯æ”¶é›†çª—å£å¤±è´¥: {e}")
        return None


def get_information_gathering_config() -> dict:
    """
    è·å–ä¿¡æ¯æ”¶é›†æ¨¡å—çš„é»˜è®¤é…ç½®
    
    Returns:
        dict: é…ç½®å­—å…¸
    """
    return {
        'enterprise_query': {
            'tianyancha_cookie': '',
            'aiqicha_cookie': ''
        },
        'asset_mapping': {
            'fofa_api_key': '',
            'hunter_api_key': '',
            'quake_api_key': ''
        },
        'unified_search': {
            'default_platforms': ['fofa', 'hunter', 'quake'],
            'default_limit': 100,
            'enable_debug': False
        }
    }


def validate_information_gathering_config(config: dict) -> bool:
    """
    éªŒè¯ä¿¡æ¯æ”¶é›†æ¨¡å—é…ç½®
    
    Args:
        config: é…ç½®å­—å…¸
        
    Returns:
        bool: é…ç½®æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        # æ£€æŸ¥å¿…è¦çš„é…ç½®é¡¹
        required_sections = ['enterprise_query', 'asset_mapping', 'unified_search']
        
        for section in required_sections:
            if section not in config:
                logging.warning(f"é…ç½®ç¼ºå°‘å¿…è¦éƒ¨åˆ†: {section}")
                return False
        
        # æ£€æŸ¥ä¼ä¸šæŸ¥è¯¢é…ç½®
        enterprise_config = config['enterprise_query']
        if not isinstance(enterprise_config, dict):
            logging.warning("ä¼ä¸šæŸ¥è¯¢é…ç½®æ ¼å¼é”™è¯¯")
            return False
        
        # æ£€æŸ¥èµ„äº§æŸ¥è¯¢é…ç½®
        asset_config = config['asset_mapping']
        if not isinstance(asset_config, dict):
            logging.warning("èµ„äº§æŸ¥è¯¢é…ç½®æ ¼å¼é”™è¯¯")
            return False
        
        # æ£€æŸ¥ç»Ÿä¸€æŸ¥è¯¢é…ç½®
        unified_config = config['unified_search']
        if not isinstance(unified_config, dict):
            logging.warning("ç»Ÿä¸€æŸ¥è¯¢é…ç½®æ ¼å¼é”™è¯¯")
            return False
        
        logging.info("ä¿¡æ¯æ”¶é›†æ¨¡å—é…ç½®éªŒè¯é€šè¿‡")
        return True
        
    except Exception as e:
        logging.error(f"éªŒè¯ä¿¡æ¯æ”¶é›†æ¨¡å—é…ç½®å¤±è´¥: {e}")
        return False


def migrate_legacy_information_gathering_data(legacy_data: dict) -> dict:
    """
    è¿ç§»æ—§ç‰ˆæœ¬çš„ä¿¡æ¯æ”¶é›†æ•°æ®åˆ°æ–°çš„æ¨¡å—åŒ–æ ¼å¼
    
    Args:
        legacy_data: æ—§ç‰ˆæœ¬æ•°æ®
        
    Returns:
        dict: è¿ç§»åçš„æ•°æ®
    """
    try:
        migrated_data = {
            'enterprise_results': [],
            'asset_results': [],
            'unified_results': {},
            'migration_info': {
                'migrated_at': str(datetime.now()),
                'source_version': 'legacy'
            }
        }
        
        # è¿ç§»ä¼ä¸šæŸ¥è¯¢ç»“æœ
        if 'tianyancha_results' in legacy_data:
            for result in legacy_data['tianyancha_results']:
                result['source'] = 'tianyancha'
                result['migrated'] = True
                migrated_data['enterprise_results'].append(result)
        
        if 'aiqicha_results' in legacy_data:
            for result in legacy_data['aiqicha_results']:
                result['source'] = 'aiqicha'
                result['migrated'] = True
                migrated_data['enterprise_results'].append(result)
        
        # è¿ç§»èµ„äº§æŸ¥è¯¢ç»“æœ
        for platform in ['fofa', 'hunter', 'quake']:
            platform_key = f'{platform}_results'
            if platform_key in legacy_data:
                for result in legacy_data[platform_key]:
                    result['source'] = platform
                    result['migrated'] = True
                    migrated_data['asset_results'].append(result)
        
        # è¿ç§»ç»Ÿä¸€æŸ¥è¯¢ç»“æœ
        if 'unified_results' in legacy_data:
            migrated_data['unified_results'] = legacy_data['unified_results']
        
        logging.info(f"æˆåŠŸè¿ç§» {len(migrated_data['enterprise_results'])} ä¸ªä¼ä¸šæŸ¥è¯¢ç»“æœ")
        logging.info(f"æˆåŠŸè¿ç§» {len(migrated_data['asset_results'])} ä¸ªèµ„äº§æŸ¥è¯¢ç»“æœ")
        
        return migrated_data
        
    except Exception as e:
        logging.error(f"è¿ç§»æ—§ç‰ˆæœ¬ä¿¡æ¯æ”¶é›†æ•°æ®å¤±è´¥: {e}")
        return {}


def export_information_gathering_results(results: dict, file_path: str, format_type: str = 'excel') -> bool:
    """
    å¯¼å‡ºä¿¡æ¯æ”¶é›†ç»“æœ
    
    Args:
        results: ç»“æœæ•°æ®
        file_path: å¯¼å‡ºæ–‡ä»¶è·¯å¾„
        format_type: å¯¼å‡ºæ ¼å¼ ('excel', 'json', 'csv')
        
    Returns:
        bool: å¯¼å‡ºæ˜¯å¦æˆåŠŸ
    """
    try:
        if format_type == 'excel':
            return _export_to_excel(results, file_path)
        elif format_type == 'json':
            return _export_to_json(results, file_path)
        elif format_type == 'csv':
            return _export_to_csv(results, file_path)
        else:
            logging.error(f"ä¸æ”¯æŒçš„å¯¼å‡ºæ ¼å¼: {format_type}")
            return False
            
    except Exception as e:
        logging.error(f"å¯¼å‡ºä¿¡æ¯æ”¶é›†ç»“æœå¤±è´¥: {e}")
        return False


def _export_to_excel(results: dict, file_path: str) -> bool:
    """
    å¯¼å‡ºåˆ°Excelæ–‡ä»¶
    """
    try:
        import pandas as pd
        
        with pd.ExcelWriter(file_path, engine='openpyxl') as writer:
            # å¯¼å‡ºä¼ä¸šæŸ¥è¯¢ç»“æœ
            if 'enterprise_results' in results and results['enterprise_results']:
                enterprise_df = pd.DataFrame(results['enterprise_results'])
                enterprise_df.to_excel(writer, sheet_name='ä¼ä¸šæŸ¥è¯¢ç»“æœ', index=False)
            
            # å¯¼å‡ºèµ„äº§æŸ¥è¯¢ç»“æœ
            if 'asset_results' in results and results['asset_results']:
                asset_df = pd.DataFrame(results['asset_results'])
                asset_df.to_excel(writer, sheet_name='èµ„äº§æŸ¥è¯¢ç»“æœ', index=False)
            
            # å¯¼å‡ºç»Ÿä¸€æŸ¥è¯¢ç»“æœ
            if 'unified_results' in results and results['unified_results']:
                unified_data = []
                for query, platforms_results in results['unified_results'].items():
                    for platform, platform_result in platforms_results.items():
                        if platform_result.get('success', False) and 'results' in platform_result:
                            for item in platform_result['results']:
                                if isinstance(item, dict):
                                    item_copy = item.copy()
                                    item_copy['query'] = query
                                    item_copy['platform'] = platform
                                    unified_data.append(item_copy)
                
                if unified_data:
                    unified_df = pd.DataFrame(unified_data)
                    unified_df.to_excel(writer, sheet_name='ç»Ÿä¸€æŸ¥è¯¢ç»“æœ', index=False)
        
        return True
        
    except Exception as e:
        logging.error(f"å¯¼å‡ºExcelæ–‡ä»¶å¤±è´¥: {e}")
        return False


def _export_to_json(results: dict, file_path: str) -> bool:
    """
    å¯¼å‡ºåˆ°JSONæ–‡ä»¶
    """
    try:
        import json
        
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        return True
        
    except Exception as e:
        logging.error(f"å¯¼å‡ºJSONæ–‡ä»¶å¤±è´¥: {e}")
        return False


def _export_to_csv(results: dict, file_path: str) -> bool:
    """
    å¯¼å‡ºåˆ°CSVæ–‡ä»¶
    """
    try:
        import pandas as pd
        
        # åˆå¹¶æ‰€æœ‰ç»“æœ
        all_data = []
        
        # æ·»åŠ ä¼ä¸šæŸ¥è¯¢ç»“æœ
        if 'enterprise_results' in results:
            all_data.extend(results['enterprise_results'])
        
        # æ·»åŠ èµ„äº§æŸ¥è¯¢ç»“æœ
        if 'asset_results' in results:
            all_data.extend(results['asset_results'])
        
        # æ·»åŠ ç»Ÿä¸€æŸ¥è¯¢ç»“æœ
        if 'unified_results' in results:
            for query, platforms_results in results['unified_results'].items():
                for platform, platform_result in platforms_results.items():
                    if platform_result.get('success', False) and 'results' in platform_result:
                        for item in platform_result['results']:
                            if isinstance(item, dict):
                                item_copy = item.copy()
                                item_copy['query'] = query
                                item_copy['platform'] = platform
                                all_data.append(item_copy)
        
        if all_data:
            df = pd.DataFrame(all_data)
            df.to_csv(file_path, index=False, encoding='utf-8-sig')
        
        return True
        
    except Exception as e:
        logging.error(f"å¯¼å‡ºCSVæ–‡ä»¶å¤±è´¥: {e}")
        return False


# å¯¼å…¥datetimeç”¨äºè¿ç§»åŠŸèƒ½
from datetime import datetime


def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ä¿¡æ¯æ”¶é›†æ¨¡å—é›†æˆåŠ©æ‰‹åŠ è½½æˆåŠŸ")
    
    # æµ‹è¯•é…ç½®éªŒè¯
    test_config = get_information_gathering_config()
    is_valid = validate_information_gathering_config(test_config)
    print(f"é»˜è®¤é…ç½®éªŒè¯ç»“æœ: {is_valid}")


if __name__ == "__main__":
    main()