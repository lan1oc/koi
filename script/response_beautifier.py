#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å“åº”æ–‡ä»¶ç¾åŒ–å·¥å…·
ç”¨äºç¾åŒ–ä¼ä¸šæŸ¥è¯¢è„šæœ¬ç”Ÿæˆçš„å“åº”æ–‡ä»¶ï¼Œæé«˜å¯è¯»æ€§
"""

import os
import json
import re
from datetime import datetime
from pathlib import Path
import argparse

class ResponseBeautifier:
    def __init__(self, output_dir):
        self.output_dir = Path(output_dir)
        self.beautified_count = 0
        self.error_count = 0
        
    def beautify_json_file(self, file_path):
        """ç¾åŒ–JSONæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ·»åŠ æ›´å¤šä¿¡æ¯å’Œç¾åŒ–æ ¼å¼
            if 'url' in data:
                # è§£æURLä¿¡æ¯
                url_info = self._parse_url_info(data['url'])
                data['url_info'] = url_info
            
            # æ·»åŠ è¯·æ±‚åˆ†æ
            if 'headers' in data:
                data['analysis'] = self._analyze_headers(data['headers'])
            
            # ç¾åŒ–æ—¶é—´æˆ³
            if 'timestamp' in data:
                data['formatted_time'] = self._format_timestamp(data['timestamp'])
            
            # é‡æ–°å†™å…¥æ–‡ä»¶ï¼Œä½¿ç”¨ç¾åŒ–çš„æ ¼å¼
            with open(file_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2, separators=(',', ': '))
            
            self.beautified_count += 1
            return True
            
        except Exception as e:
            print(f"âŒ ç¾åŒ–JSONæ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            self.error_count += 1
            return False
    
    def beautify_content_file(self, file_path):
        """ç¾åŒ–å†…å®¹æ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # å°è¯•è§£æä¸ºJSONå¹¶ç¾åŒ–
            try:
                json_data = json.loads(content)
                beautified_content = json.dumps(json_data, ensure_ascii=False, indent=2, separators=(',', ': '))
                
                # æ·»åŠ æ–‡ä»¶å¤´éƒ¨ä¿¡æ¯
                header = self._create_content_header(file_path, "JSON")
                final_content = header + "\n" + beautified_content
                
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONï¼Œåˆ™æ·»åŠ HTMLç¾åŒ–æˆ–å…¶ä»–æ ¼å¼å¤„ç†
                if '<html' in content.lower() or '<!doctype' in content.lower():
                    final_content = self._beautify_html_content(content, file_path)
                else:
                    # æ™®é€šæ–‡æœ¬ï¼Œæ·»åŠ å¤´éƒ¨ä¿¡æ¯
                    header = self._create_content_header(file_path, "TEXT")
                    final_content = header + "\n" + content
            
            # å†™å›æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(final_content)
            
            self.beautified_count += 1
            return True
            
        except Exception as e:
            print(f"âŒ ç¾åŒ–å†…å®¹æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
            self.error_count += 1
            return False
    
    def _parse_url_info(self, url):
        """è§£æURLä¿¡æ¯"""
        info = {
            "domain": "",
            "path": "",
            "query_params": {},
            "api_type": "unknown"
        }
        
        try:
            from urllib.parse import urlparse, parse_qs
            parsed = urlparse(url)
            info["domain"] = parsed.netloc
            info["path"] = parsed.path
            info["query_params"] = {k: v[0] if len(v) == 1 else v for k, v in parse_qs(parsed.query).items()}
            
            # åˆ¤æ–­APIç±»å‹
            if "tianyancha.com" in parsed.netloc:
                if "/nsearch" in parsed.path:
                    info["api_type"] = "ä¼ä¸šæœç´¢"
                elif "/icpRecordList" in parsed.path:
                    info["api_type"] = "ICPå¤‡æ¡ˆæŸ¥è¯¢"
                elif "/appbkinfo" in parsed.path:
                    info["api_type"] = "APPå¤‡æ¡ˆä¿¡æ¯"
                elif "/list" in parsed.path:
                    info["api_type"] = "åˆ—è¡¨æŸ¥è¯¢"
                else:
                    info["api_type"] = "å¤©çœ¼æŸ¥API"
            elif "aiqicha.baidu.com" in parsed.netloc:
                info["api_type"] = "çˆ±ä¼æŸ¥API"
            
        except Exception:
            pass
        
        return info
    
    def _analyze_headers(self, headers):
        """åˆ†æå“åº”å¤´"""
        analysis = {
            "content_type": headers.get("Content-Type", "unknown"),
            "encoding": "unknown",
            "cache_policy": "unknown",
            "server_info": headers.get("Server", "unknown"),
            "security_headers": []
        }
        
        # åˆ†æå†…å®¹ç±»å‹å’Œç¼–ç 
        content_type = headers.get("Content-Type", "")
        if "charset=" in content_type:
            analysis["encoding"] = content_type.split("charset=")[1].split(";")[0]
        
        # åˆ†æç¼“å­˜ç­–ç•¥
        cache_control = headers.get("cache-control", headers.get("Cache-Control", ""))
        if cache_control:
            analysis["cache_policy"] = cache_control
        
        # æ£€æŸ¥å®‰å…¨å¤´
        security_headers = ["Access-Control-Allow-Origin", "X-Frame-Options", "X-Content-Type-Options"]
        for header in security_headers:
            if header in headers:
                analysis["security_headers"].append({
                    "name": header,
                    "value": headers[header]
                })
        
        return analysis
    
    def _format_timestamp(self, timestamp):
        """æ ¼å¼åŒ–æ—¶é—´æˆ³"""
        try:
            # å‡è®¾æ—¶é—´æˆ³æ ¼å¼ä¸º YYYYMMDD_HHMMSS
            dt = datetime.strptime(timestamp, "%Y%m%d_%H%M%S")
            return {
                "readable": dt.strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S"),
                "iso": dt.isoformat(),
                "weekday": dt.strftime("%A"),
                "weekday_cn": ["å‘¨ä¸€", "å‘¨äºŒ", "å‘¨ä¸‰", "å‘¨å››", "å‘¨äº”", "å‘¨å…­", "å‘¨æ—¥"][dt.weekday()]
            }
        except Exception:
            return {"readable": timestamp, "iso": timestamp}
    
    def _create_content_header(self, file_path, content_type):
        """åˆ›å»ºå†…å®¹æ–‡ä»¶å¤´éƒ¨"""
        file_name = Path(file_path).name
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        header = f"""/*
 * æ–‡ä»¶å: {file_name}
 * å†…å®¹ç±»å‹: {content_type}
 * ç¾åŒ–æ—¶é—´: {timestamp}
 * ç¾åŒ–å·¥å…·: ResponseBeautifier v1.0
 * ================================================
 */"""
        return header
    
    def _beautify_html_content(self, content, file_path):
        """ç¾åŒ–HTMLå†…å®¹"""
        try:
            # ç®€å•çš„HTMLç¾åŒ–
            import re
            
            # æ·»åŠ ç¼©è¿›
            content = re.sub(r'><', '>\n<', content)
            
            # æ·»åŠ æ–‡ä»¶å¤´
            header = self._create_content_header(file_path, "HTML")
            return header + "\n" + content
            
        except Exception:
            header = self._create_content_header(file_path, "HTML")
            return header + "\n" + content
    
    def beautify_directory(self):
        """ç¾åŒ–æ•´ä¸ªç›®å½•"""
        print(f"ğŸ¨ å¼€å§‹ç¾åŒ–ç›®å½•: {self.output_dir}")
        print("="*60)
        
        # å¤„ç†æ‰€æœ‰JSONæ–‡ä»¶
        json_files = list(self.output_dir.glob("*_headers.json"))
        for json_file in json_files:
            print(f"ğŸ“„ ç¾åŒ–JSONæ–‡ä»¶: {json_file.name}")
            self.beautify_json_file(json_file)
        
        # å¤„ç†æ‰€æœ‰å†…å®¹æ–‡ä»¶
        content_files = list(self.output_dir.glob("*_content.txt"))
        for content_file in content_files:
            print(f"ğŸ“„ ç¾åŒ–å†…å®¹æ–‡ä»¶: {content_file.name}")
            self.beautify_content_file(content_file)
        
        # åˆ›å»ºæ±‡æ€»æŠ¥å‘Š
        self.create_summary_report()
        
        print("="*60)
        print(f"âœ… ç¾åŒ–å®Œæˆï¼")
        print(f"ğŸ“Š æˆåŠŸå¤„ç†: {self.beautified_count} ä¸ªæ–‡ä»¶")
        if self.error_count > 0:
            print(f"âŒ å¤„ç†å¤±è´¥: {self.error_count} ä¸ªæ–‡ä»¶")
    
    def create_summary_report(self):
        """åˆ›å»ºæ±‡æ€»æŠ¥å‘Š"""
        try:
            report_path = self.output_dir / "ç¾åŒ–æŠ¥å‘Š.md"
            
            # æ”¶é›†æ–‡ä»¶ä¿¡æ¯
            json_files = list(self.output_dir.glob("*_headers.json"))
            content_files = list(self.output_dir.glob("*_content.txt"))
            
            report_content = f"""# å“åº”æ–‡ä»¶ç¾åŒ–æŠ¥å‘Š

## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯
- **ç¾åŒ–æ—¶é—´**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}
- **å¤„ç†ç›®å½•**: {self.output_dir}
- **JSONæ–‡ä»¶æ•°é‡**: {len(json_files)}
- **å†…å®¹æ–‡ä»¶æ•°é‡**: {len(content_files)}
- **æˆåŠŸå¤„ç†**: {self.beautified_count} ä¸ªæ–‡ä»¶
- **å¤„ç†å¤±è´¥**: {self.error_count} ä¸ªæ–‡ä»¶

## ğŸ“ æ–‡ä»¶åˆ—è¡¨

### JSONå“åº”å¤´æ–‡ä»¶
"""
            
            for json_file in sorted(json_files):
                try:
                    with open(json_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    url_info = data.get('url_info', {})
                    api_type = url_info.get('api_type', 'æœªçŸ¥')
                    status_code = data.get('status_code', 'æœªçŸ¥')
                    
                    report_content += f"- **{json_file.name}**\n"
                    report_content += f"  - APIç±»å‹: {api_type}\n"
                    report_content += f"  - çŠ¶æ€ç : {status_code}\n"
                    report_content += f"  - URL: {data.get('url', 'æœªçŸ¥')}\n\n"
                except Exception:
                    report_content += f"- **{json_file.name}** (è§£æå¤±è´¥)\n\n"
            
            report_content += "\n### å†…å®¹å“åº”æ–‡ä»¶\n"
            
            for content_file in sorted(content_files):
                file_size = content_file.stat().st_size
                size_str = f"{file_size:,} å­—èŠ‚"
                if file_size > 1024:
                    size_str += f" ({file_size/1024:.1f} KB)"
                
                report_content += f"- **{content_file.name}**\n"
                report_content += f"  - æ–‡ä»¶å¤§å°: {size_str}\n\n"
            
            report_content += f"""
## ğŸ¨ ç¾åŒ–è¯´æ˜

### JSONæ–‡ä»¶ç¾åŒ–å†…å®¹
1. **URLä¿¡æ¯è§£æ**: è‡ªåŠ¨è§£æåŸŸåã€è·¯å¾„ã€æŸ¥è¯¢å‚æ•°
2. **APIç±»å‹è¯†åˆ«**: æ ¹æ®URLè‡ªåŠ¨è¯†åˆ«APIç±»å‹
3. **å“åº”å¤´åˆ†æ**: åˆ†æå†…å®¹ç±»å‹ã€ç¼–ç ã€ç¼“å­˜ç­–ç•¥ç­‰
4. **æ—¶é—´æ ¼å¼åŒ–**: å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå¯è¯»æ ¼å¼
5. **JSONæ ¼å¼åŒ–**: ä½¿ç”¨2ç©ºæ ¼ç¼©è¿›ï¼Œä¸­æ–‡ä¸è½¬ä¹‰

### å†…å®¹æ–‡ä»¶ç¾åŒ–å†…å®¹
1. **JSONè‡ªåŠ¨æ ¼å¼åŒ–**: æ£€æµ‹JSONå†…å®¹å¹¶è‡ªåŠ¨æ ¼å¼åŒ–
2. **HTMLç®€å•ç¾åŒ–**: ä¸ºHTMLå†…å®¹æ·»åŠ æ¢è¡Œ
3. **æ–‡ä»¶å¤´ä¿¡æ¯**: ä¸ºæ‰€æœ‰æ–‡ä»¶æ·»åŠ ç¾åŒ–ä¿¡æ¯å¤´
4. **ç¼–ç ç»Ÿä¸€**: ç»Ÿä¸€ä½¿ç”¨UTF-8ç¼–ç 

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}*
*ç¾åŒ–å·¥å…·: ResponseBeautifier v1.0*
"""
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"ğŸ“‹ æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    parser = argparse.ArgumentParser(description="å“åº”æ–‡ä»¶ç¾åŒ–å·¥å…·")
    parser.add_argument("directory", help="è¦ç¾åŒ–çš„ç›®å½•è·¯å¾„")
    
    args = parser.parse_args()
    
    if not os.path.exists(args.directory):
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {args.directory}")
        return
    
    beautifier = ResponseBeautifier(args.directory)
    beautifier.beautify_directory()

if __name__ == "__main__":
    main()